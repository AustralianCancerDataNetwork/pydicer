{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Data Objects\n",
    "\n",
    "While PyDicer primarily deals with converting data objects from DICOM, there are instances where\n",
    "you may want to generate a new data object and have it integrated into your PyDicer dataset.\n",
    "\n",
    "Some examples of when you may want to do this are:\n",
    "- Generate a new dose grid with EQD2 correction applied.\n",
    "- Generate a structure set of auto-segmented structures.\n",
    "- Generate a Pseudo-CT image from an MRI.\n",
    "\n",
    "In this guide we show you how to generate new data objects to help you perform tasks such as those\n",
    "described in the examples mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pydicer import PyDicer\n",
    "except ImportError:\n",
    "    !pip install pydicer\n",
    "    from pydicer import PyDicer\n",
    "\n",
    "from pathlib import Path\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from pydicer.utils import fetch_converted_test_data, load_object_metadata, read_simple_itk_image\n",
    "\n",
    "working_directory = fetch_converted_test_data(\"./testdata_hnscc\", dataset=\"HNSCC\")\n",
    "\n",
    "pydicer = PyDicer(working_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dose Objects\n",
    "\n",
    "In the following cell, we:\n",
    "- Iterate over each dose grid in our dataset\n",
    "- Load the dose grid using SimpleITK\n",
    "- Apply EQD2 dose correction (hard coded for demonstration purposes)\n",
    "- Save the corrected dose as a new object in our dataset\n",
    "\n",
    "Once the dose object is saved, when you compute DVHs and dose metrics, this new dose will appear\n",
    "in that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_beta = 2\n",
    "\n",
    "df = pydicer.read_converted_data()\n",
    "df_doses = df[df[\"modality\"] == \"RTDOSE\"]\n",
    "\n",
    "for _, dose_row in df_doses.iterrows():\n",
    "    if \"EQD2_ab\" in dose_row.hashed_uid:\n",
    "        # This is an already scaled dose\n",
    "        continue\n",
    "\n",
    "    df_linked_plan = df[df[\"sop_instance_uid\"] == dose_row.referenced_sop_instance_uid]\n",
    "\n",
    "    linked_plan = df_linked_plan.iloc[0]\n",
    "    ds_plan = load_object_metadata(linked_plan)\n",
    "\n",
    "    # Read the planned fractions from the plan object\n",
    "    fractions = int(ds_plan.FractionGroupSequence[0].NumberOfFractionsPlanned)\n",
    "\n",
    "    print(f\"{dose_row.patient_id} has {fractions} fractions\")\n",
    "\n",
    "    # Load the dose grid\n",
    "    dose_path = Path(dose_row.path).joinpath(\"RTDOSE.nii.gz\")\n",
    "    dose = sitk.ReadImage(str(dose_path))\n",
    "    dose = sitk.Cast(dose, sitk.sitkFloat64)\n",
    "\n",
    "    dose_id = f\"{dose_row.hashed_uid}_EQD2_ab{alpha_beta}\"\n",
    "\n",
    "    if len(df_doses[df_doses.hashed_uid == dose_id]) > 0:\n",
    "        print(f\"Already converted dose for {dose_id}\")\n",
    "        continue\n",
    "\n",
    "    # Apply the EQD2 correction\n",
    "    eqd2_dose = dose * (((dose / fractions) + alpha_beta) / (2 + alpha_beta))\n",
    "\n",
    "    # Save off the new dose grid\n",
    "    try:\n",
    "        print(f\"Saving dose grid with ID: {dose_id}\")\n",
    "        pydicer.add_dose_object(\n",
    "            eqd2_dose, dose_id, dose_row.patient_id, linked_plan, dose_row.for_uid\n",
    "        )\n",
    "    except SystemError:\n",
    "        print(f\"Dose object {dose_id} already exists!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load our data objects, and check that our new dose grids are stored alongside our\n",
    "converted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pydicer.read_converted_data()\n",
    "df[df.modality==\"RTDOSE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Structure Set Objects\n",
    "\n",
    "In this example, we:\n",
    "- Iterate over each CT image in our dataset\n",
    "- Load the CT image using SimpleITK, and apply a threshold to segment bones\n",
    "- Save the segmented bones as a new structure set object\n",
    "\n",
    "> Note: This specific functionality is supported by the auto-segmentation inference module. If you\n",
    "> are using this to generate auto-segmentations it is recommended you use that functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_threshold = 300 # Set threshold at 300 HU\n",
    "\n",
    "df = pydicer.read_converted_data()\n",
    "df_cts = df[df[\"modality\"] == \"CT\"]\n",
    "\n",
    "for idx, ct_row in df_cts.iterrows():\n",
    "\n",
    "    # Load the image\n",
    "    img = read_simple_itk_image(ct_row)\n",
    "\n",
    "    # Apply the threshold\n",
    "    bone_mask = img > bone_threshold\n",
    "\n",
    "    # Save the mask in a new structure set\n",
    "    structure_set_id = f\"bones_{ct_row.hashed_uid}\"\n",
    "    new_structure_set = {\n",
    "        \"bones\": bone_mask\n",
    "    }\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(f\"Saving structure set with ID: {structure_set_id}\")\n",
    "        pydicer.add_structure_object(\n",
    "            new_structure_set,\n",
    "            structure_set_id,\n",
    "            ct_row.patient_id,\n",
    "            ct_row,\n",
    "        )\n",
    "    except SystemError:\n",
    "        print(f\"Structure Set {structure_set_id} already exists!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load out data objects to see if we have our new structure sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pydicer.read_converted_data()\n",
    "df[df.modality==\"RTSTRUCT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also run the visualise module. Use the `force=False` flag to ensure that only the newly\n",
    "generated objects are visualised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydicer.visualise.visualise(force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look inside the `testdata_hnscc/data` directory for the new structure set folders. See the\n",
    "visualised snapshot to check that our bone segmentation worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Image Objects\n",
    "\n",
    "In this example, we:\n",
    "- Iterate over each CT image in our dataset\n",
    "- Load the CT image using SimpleITK, and apply a Laplacian Sharpening image filter to it\n",
    "- Save the image as a new image object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pydicer.read_converted_data()\n",
    "df_cts = df[df[\"modality\"] == \"CT\"]\n",
    "\n",
    "for idx, ct_row in df_cts.iterrows():\n",
    "\n",
    "    # Load the image\n",
    "    img = read_simple_itk_image(ct_row)\n",
    "\n",
    "    # Sharpen the image\n",
    "    img_sharp = sitk.LaplacianSharpening(img)\n",
    "\n",
    "    # Save the sharpened image\n",
    "    img_id = f\"sharp_{ct_row.hashed_uid}\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Saving image with ID: {img_id}\")\n",
    "        pydicer.add_image_object(\n",
    "            img_sharp,\n",
    "            img_id,\n",
    "            ct_row.modality,\n",
    "            ct_row.patient_id,\n",
    "            for_uid=ct_row.for_uid\n",
    "        )\n",
    "    except SystemError:\n",
    "        print(f\"Image {img_id} already exists!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualise the images and produce snapshots once more. Find the sharpen images in the\n",
    "working directory. Can you see the difference between the sharpened CT and the original?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydicer.visualise.visualise(force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "814af119db7f8f2860617be3dcd1d37c560587d11c65bd58c45b1679d3ee6ea4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('pydicer': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
