{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Auto-segmentation Inference & Analysis\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AustralianCancerDataNetwork/pydicer/blob/main/examples/AutoSegmentation.ipynb)\n",
                "\n",
                "A common task when working the medical imaging data, it to run an auto-segmentation model\n",
                "(inference) on the images in your dataset. If you have manual definitions of the same structures\n",
                "available in your dataset, you will typically want to compare the auto and the manual\n",
                "segmentations, computing metrics and produce plots and visualisation.\n",
                "\n",
                "This example notebook will guide you through the process of performing model inference and analysis\n",
                "of those structures. We will use a single atlas-based segmentation model for demonstration\n",
                "purposes.\n",
                "\n",
                "> Warning: The auto-segmentation results produced by the example in this notebook are poor. The\n",
                "> atlas based segmentation function is optimised for runtime is purely provided to demonstrate how\n",
                "> to run and analyse an auto-segmentation model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    from pydicer import PyDicer\n",
                "except ImportError:\n",
                "    !pip install pydicer\n",
                "    from pydicer import PyDicer\n",
                "\n",
                "import os\n",
                "import logging\n",
                "\n",
                "from pathlib import Path\n",
                "\n",
                "import SimpleITK as sitk\n",
                "\n",
                "from platipy.imaging.registration.utils import apply_transform\n",
                "from platipy.imaging.registration.linear import linear_registration\n",
                "from platipy.imaging.registration.deformable import fast_symmetric_forces_demons_registration\n",
                "\n",
                "from pydicer.utils import fetch_converted_test_data\n",
                "\n",
                "from pydicer.generate.segmentation import segment_image, read_all_segmentation_logs\n",
                "\n",
                "from pydicer.analyse.compare import (\n",
                "    compute_contour_similarity_metrics,\n",
                "    get_all_similarity_metrics_for_dataset,\n",
                "    prepare_similarity_metric_analysis\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup PyDicer\n",
                "\n",
                "For this example, we will use the LCTSC test data which has already been converted using PyDicer.\n",
                "We also initialise our PyDicer object."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "working_directory = fetch_converted_test_data(\"./lctsc_autoseg\", dataset=\"LCTSC\")\n",
                "pydicer = PyDicer(working_directory)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prepare Atlas\n",
                "\n",
                "Since we will use a single atlas-based segmentation model, we must\n",
                "split our data, selecting one case as our `atlas` and the remaining cases as the `validation` set.\n",
                "We use the PyDicer `dataset preparation` module to split our dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pydicer.read_converted_data()\n",
                "\n",
                "# Specify the patient ID to use as the atlas case\n",
                "atlas_dataset = \"atlas\"\n",
                "atlas_case  = \"LCTSC-Train-S1-001\"\n",
                "df_atlas = df[df.patient_id==atlas_case]\n",
                "\n",
                "# And the remaining cases will make up our validation set\n",
                "validation_dataset = \"validation\"\n",
                "df_validation = df[df.patient_id!=atlas_case]\n",
                "\n",
                "# Use the dataset preparation module to prepare these two data subsets\n",
                "pydicer.dataset.prepare_from_dataframe(atlas_dataset, df_atlas)\n",
                "pydicer.dataset.prepare_from_dataframe(validation_dataset, df_validation)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Define Segmentation Function\n",
                "\n",
                "Now that our `atlas` and `validation` sets are ready, we will define our function which will run\n",
                "our simple single atlas-based auto-segmentation model for us. This example uses the [atlas-based\n",
                "segmentation tools available in PlatiPy](https://pyplati.github.io/platipy/_examples/atlas_segmentation.html#).\n",
                "\n",
                "In a real-world scenario, you will have your own segmentation model you wish to apply. You should\n",
                "integrate this model into such a function which accepts an image and returns a dictionary of\n",
                "structures.\n",
                "\n",
                "To get started, we recommend you try running the [TotalSegmentator](https://github.com/wasserth/TotalSegmentator) \n",
                "model on your CT data. PyDicer already has a function ready which runs this model, check out\n",
                "[run_total_segmentator](https://australiancancerdatanetwork.github.io/pydicer/generate.html#pydicer.generate.models.run_total_segmentator)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def single_atlas_segmentation(img):\n",
                "    \"\"\"Segment an image using a single atlas case\n",
                "\n",
                "    Args:\n",
                "        img (SimpleITK.Image): The SimpleITK image to segment.\n",
                "\n",
                "    Returns:\n",
                "        dict: The segmented structure dictionary\n",
                "    \"\"\"\n",
                "\n",
                "    # Load the atlas case image\n",
                "    atlas_img_row = df_atlas[df_atlas.modality==\"CT\"].iloc[0]\n",
                "    atlas_img = sitk.ReadImage(str(Path(atlas_img_row.path).joinpath(\"CT.nii.gz\")))\n",
                "\n",
                "    # Load the atlas case structures\n",
                "    atlas_structures = {}\n",
                "    atlas_struct_row = df_atlas[df_atlas.modality==\"RTSTRUCT\"].iloc[0]\n",
                "    for struct_path in Path(atlas_struct_row.path).glob(\"*.nii.gz\"):\n",
                "        struct_name = struct_path.name.replace(\".nii.gz\", \"\")\n",
                "        atlas_structures[struct_name] = sitk.ReadImage(str(struct_path))\n",
                "\n",
                "    # Use a simple linear (rigid) registration to align the input image with the atlas image\n",
                "    img_ct_atlas_reg_linear, tfm_linear = linear_registration(\n",
                "        fixed_image = img,\n",
                "        moving_image = atlas_img,\n",
                "        reg_method='similarity',\n",
                "        metric='mean_squares',\n",
                "        optimiser='gradient_descent',\n",
                "        shrink_factors=[4, 2],\n",
                "        smooth_sigmas=[2, 0],\n",
                "        sampling_rate=1.0,\n",
                "        number_of_iterations=50,\n",
                "    )\n",
                "\n",
                "    # Perform a fast deformable registration\n",
                "    img_ct_atlas_reg_dir, tfm_dir, dvf = fast_symmetric_forces_demons_registration(\n",
                "        img,\n",
                "        img_ct_atlas_reg_linear,\n",
                "        ncores=4,\n",
                "        isotropic_resample=True,\n",
                "        resolution_staging=[4],\n",
                "        iteration_staging=[20],\n",
                "    )\n",
                "\n",
                "    # Combine the two transforms\n",
                "    tfm_combined = sitk.CompositeTransform((tfm_linear, tfm_dir))\n",
                "\n",
                "    # Apply the transform to the atlas structures\n",
                "    auto_segmentations = {}\n",
                "    for s in atlas_structures:\n",
                "        auto_segmentations[s] = apply_transform(\n",
                "            atlas_structures[s],\n",
                "            reference_image=img,\n",
                "            transform=tfm_combined\n",
                "        )\n",
                "\n",
                "    return auto_segmentations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Auto-segmentation\n",
                "\n",
                "The `segment_dataset` function will run over all images in our dataset and will pass the images to\n",
                "a function we define for segmentation. We pass in the name of our `validation_dataset` so that only\n",
                "the images in this dataset will be segmented."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "segment_id = \"atlas\" # Used to generate the ID of the resulting auto-segmented structure sets\n",
                "\n",
                "pydicer.segment_dataset(segment_id, single_atlas_segmentation, dataset_name=validation_dataset)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can use PyDicer's `visualisation` module to produce snapshots of the auto-segmentations\n",
                "produced."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pydicer.visualise.visualise(force=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Read Segmentation Logs\n",
                "\n",
                "After running the auto-segmentation on across the dataset, we can fetch the logs to confirm that\n",
                "everything went well. This will also let us inspect the runtime of the segmentation. In case\n",
                "something went wrong, we can use these logs to help debug the issue."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read the segmentation log DataFrame\n",
                "df_logs = read_all_segmentation_logs(working_directory)\n",
                "df_logs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use some Pandas magic to produce some stats on the segmentation runtime\n",
                "df_success = df_logs[df_logs.success_flag]\n",
                "agg_stats = [\"mean\", \"std\", \"max\", \"min\", \"count\"]\n",
                "df_success[[\"segment_id\", \"total_time_seconds\"]].groupby(\"segment_id\").agg(agg_stats)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Auto-segmentation Analysis\n",
                "\n",
                "Now that our auto-segmentation model has been run on our `validation` set, we can compare these\n",
                "structures to the manual structures available on this dataset. PyDicer provides functionality to\n",
                "compute similarity metrics, but we must first prepare a DataFrame containing our auto structure\n",
                "sets (`df_target`) and a separate DataFrame with our manual structure sets (`df_reference`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pydicer.read_converted_data(dataset_name=validation_dataset)\n",
                "df_structs = df[df.modality==\"RTSTRUCT\"]\n",
                "\n",
                "df_reference = df_structs[~df_structs.hashed_uid.str.startswith(f\"atlas_\")]\n",
                "df_target = df_structs[df_structs.hashed_uid.str.startswith(f\"atlas_\")]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_reference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_target"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Compute Similarity \n",
                "\n",
                "We use the `compute_contour_similarity_metrics` function to compute the metrics comparing our\n",
                "target structures to our reference structures.\n",
                "\n",
                "We can specify which metrics we want to compute, in this example we compute the Dice Similarity\n",
                "Coefficient (DSC), Hausdorff Distance, Mean Surface Distance and the Surface DSC.\n",
                "\n",
                "> Structure names must match exactly, so we use a structure name mapping to standardise our\n",
                "> structure names prior to computing the similarity metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add our structure name mapping\n",
                "mapping_id = \"nnunet_lctsc\"\n",
                "mapping = {\n",
                "    \"Esophagus\": [],\n",
                "    \"Heart\": [],\n",
                "    \"Lung_L\": [\"L_Lung\", \"Lung_Left\"],\n",
                "    \"Lung_R\": [\"Lung_Right\"],\n",
                "    \"SpinalCord\": [\"SC\"],\n",
                "}\n",
                "pydicer.add_structure_name_mapping(mapping, mapping_id)\n",
                "\n",
                "# Specify the metrics we want to compute\n",
                "compute_metrics = [\"DSC\", \"hausdorffDistance\", \"meanSurfaceDistance\", \"surfaceDSC\"]\n",
                "\n",
                "# Compute the similarity metrics\n",
                "compute_contour_similarity_metrics(\n",
                "    df_target,\n",
                "    df_reference,\n",
                "    segment_id,\n",
                "    compute_metrics=compute_metrics,\n",
                "    mapping_id=mapping_id\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Fetch the similarity metrics\n",
                "\n",
                "Here we fetch the metrics computed and output some stats. Note that if a segmentation fails, \n",
                "surface metrics will return NaN and will be excluded from these stats."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fetch the similarity metrics\n",
                "df_metrics = get_all_similarity_metrics_for_dataset(\n",
                "    working_directory,\n",
                "    dataset_name=validation_dataset,\n",
                "    structure_mapping_id=mapping_id\n",
                ")\n",
                "\n",
                "# Aggregate the stats using Pandas\n",
                "df_metrics[\n",
                "    [\"segment_id\", \"structure\", \"metric\", \"value\"]\n",
                "    ].groupby(\n",
                "        [\"segment_id\", \"structure\", \"metric\"]\n",
                "    ).agg(\n",
                "        [\"mean\", \"std\", \"min\", \"max\", \"count\"]\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Perform Analysis\n",
                "\n",
                "There are various plots and visualisations you may wish to produce following computation of\n",
                "similarity metrics. The `prepare_similarity_metric_analysis` will generate several useful plots\n",
                "which will serve as a useful starting point when analysing your auto-segmentation results.\n",
                "\n",
                "Plots are generated in a directory you provide. In this example, plots and tables (`.csv`) are\n",
                "output in the `testdata_lctsc/analysis/atlas` directory. Run the following cell, then navigate\n",
                "to that directory to explore the results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "analysis_output_directory = working_directory.joinpath(\n",
                "    \"analysis\",\n",
                "    segment_id\n",
                ")\n",
                "analysis_output_directory.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "prepare_similarity_metric_analysis(\n",
                "    working_directory,\n",
                "    analysis_output_directory=analysis_output_directory,\n",
                "    dataset_name=validation_dataset,\n",
                "    structure_mapping_id=mapping_id\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "814af119db7f8f2860617be3dcd1d37c560587d11c65bd58c45b1679d3ee6ea4"
        },
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}